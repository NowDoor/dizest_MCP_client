{"apps": {"i40doozgbbeemgq4": {"id": "i40doozgbbeemgq4", "title": "define workflow", "version": "1.0.0", "description": "", "cdn": {"js": [], "css": []}, "inputs": [{"type": "variable", "name": "file_path", "inputtype": "file", "description": "", "conf": false}], "outputs": [{"name": "flow"}, {"name": "file_path"}], "code": "import json\n\nwith open(file_path, 'r', encoding='utf-8') as file:\n    content = file.read()\n\ndata = json.loads(content)\n\n# \ubaa8\ub4e0 \uc571\uc758 title\ub9cc \ucd94\ucd9c\ntitles = [app[\"title\"] for app in data[\"apps\"].values()]\ncode = [app[\"code\"] for app in data[\"apps\"].values()]\n\nflow = {}\nfor i in range(len(titles)):\n    flow[titles[i]] = code[i]\n\nprint(flow)", "api": "", "html": "", "js": "", "css": ""}, "b6uew1c7epof7qpe": {"id": "b6uew1c7epof7qpe", "title": "agent test", "version": "1.0.0", "description": "", "cdn": {"js": [], "css": []}, "inputs": [{"type": "output", "name": "query"}, {"type": "variable", "name": "server_url", "inputtype": "text", "description": ""}, {"type": "variable", "name": "file_path", "inputtype": "text", "description": ""}, {"type": "variable", "name": "query", "inputtype": "textarea", "description": "", "conf": false}], "outputs": [], "code": "import os\nimport operator\nimport functools\nimport uuid\nimport json\nimport time\nfrom typing import Sequence, Literal\nfrom typing import Annotated\nfrom typing_extensions import TypedDict\nfrom pydantic import BaseModel\nimport uuid\nfrom typing import Annotated, Literal, Sequence, TypedDict\nfrom langchain_core.messages import BaseMessage, HumanMessage\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.prompts import MessagesPlaceholder\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langchain_anthropic import ChatAnthropic\n\n# --- MCP client setup ---\nimport asyncio\nfrom mcp import ClientSession\nfrom mcp.client.stdio import stdio_client\nfrom langchain_mcp_adapters.tools import load_mcp_tools\nfrom mcp import StdioServerParameters\nfrom langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langchain.tools import StructuredTool\nfrom langgraph.prebuilt import create_react_agent\n\nimport configparser\nimport time\n\nconfig = configparser.ConfigParser()\nconfig.read('config/key.ini')\n\n\n# \uc0ac\uc6a9\uc790 \uc785\ub825\nquery = dizest.input('query')\ntextfile = dizest.input('file_path')\nserver_url = dizest.input('server_url')\n\n# \uae30\ubcf8\uac12 \uc124\uc815\nquery = \"\"\"\uc548\ub155\"\"\" if not query else query\nfile_path = \"\"\"\"\"\" if not textfile else textfile\nserver_url = \"\"\"\"\"\" if not server_url else server_url\n\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_xai import ChatXAI\n'''\nmodel = ChatXAI(\n    xai_api_key=config.get('key', 'grok'),\n    model=\"grok-3-beta\",\n)\n'''\nfrom langchain_openai import ChatOpenAI\n\nmodel = ChatOpenAI(\n            api_key=config.get('key', 'gpt'),\n            model='o4-mini',\n            **{},\n        )\n\nMAX_HISTORY_LENGTH = 2  # Message history limit\n\ndef truncate_messages(messages):\n    return messages[-MAX_HISTORY_LENGTH:]\n\n# --- State and Type Definitions ---\nclass AgentState(TypedDict):\n    messages: Annotated[Sequence[BaseMessage], operator.add]\n    next: str\n    file_path: str\n    parallel_required: bool\n    code_blocks: dict\n    iteration_count: int\n    connections: dict\n    connection_type: str\n\n# --- Supervisor routing response model ---\nclass RouteResponse(BaseModel):\n    next: Literal[\"FINISH\", \"Researcher\", \"Coder\", \"File_Analyzer\"]\n\n# --- Flow connection type definition ---\nclass ConnectionType(BaseModel):\n    connection_type: Literal[\"serial\", \"parallel\", \"mixed\"]\n\nasync def generate_workflow(query, file_path):\n    async with MultiServerMCPClient(\n        {\n            \"test\": {\n                \"url\": f\"http://{server_url}:8000/sse\",\n                \"transport\": \"sse\",\n            }\n        }\n    ) as client:\n        # --- Get tools from MCP ---\n        tools = client.get_tools()\n        tavily_search = next((tool for tool in tools if tool.name == \"tavily_search\"), None)\n        analyze_parallelization = next((tool for tool in tools if tool.name == \"analyze_parallelization\"), None)\n        create_flow = next((tool for tool in tools if tool.name == \"create_flow\"), None)\n        analyze_existing_file = next((tool for tool in tools if tool.name == \"analyze_existing_file\"), None)\n        python_repl_tool = next((tool for tool in tools if tool.name == \"python_repl_tool\"), None)\n\n        # --- File Analyzer Agent ---\n        file_analyzer_system_prompt = \"\"\"\n        \ub2f9\uc2e0\uc740 \uae30\uc874 \ucf54\ub4dc \ud30c\uc77c\uc744 \ubd84\uc11d\ud558\ub294 \uc804\ubb38\uac00\uc785\ub2c8\ub2e4. \ub2e4\uc74c \uaddc\uce59\uc744 \ub530\ub974\uc138\uc694:\n\n        1.{} \uacbd\ub85c\uc758 \ub0b4\uc6a9\uc744 \ubd84\uc11d\ud558\uace0 \uc774\ud574\ud569\ub2c8\ub2e4.\n        2. \ud30c\uc77c\uc774 \uc874\uc7ac\ud558\uba74 \ub0b4\ubd80 \uad6c\uc870, \uc571 \ucf54\ub4dc, \uc5f0\uacb0 \ubc29\uc2dd \ub4f1\uc744 \uc0c1\uc138\ud788 \ubd84\uc11d\ud569\ub2c8\ub2e4.\n        3. \ud30c\uc77c\uc774 \uc5c6\uac70\ub098 \ub0b4\uc6a9\uc774 \uc720\ud6a8\ud558\uc9c0 \uc54a\uc73c\uba74 \uadf8 \uc0ac\uc2e4\uc744 \ubcf4\uace0\ud569\ub2c8\ub2e4.\n        4. \ubd84\uc11d \uacb0\uacfc\ub294 \ub2e4\uc74c\uc744 \ud3ec\ud568\ud574\uc57c \ud569\ub2c8\ub2e4:\n           - \ud30c\uc77c \uc874\uc7ac \uc5ec\ubd80\n           - \ud30c\uc77c \uad6c\uc870 (\uc571, \uc5f0\uacb0 \ub4f1)\n           - \uae30\uc874 \uc571\uc758 \ubaa9\uc801\uacfc \uae30\ub2a5\n           - \uc5f0\uacb0 \ubc29\uc2dd (\uc9c1\ub82c/\ubcd1\ub82c/\ud63c\ud569)\n           - \uc0c8 \uae30\ub2a5\uc744 \ucd94\uac00\ud558\uac70\ub098 \uc218\uc815\ud560 \ub54c\uc758 \uad8c\uc7a5 \uc0ac\ud56d\n\n        5. \ubd84\uc11d\ud55c \ub0b4\uc6a9\uc744 \ubc14\ud0d5\uc73c\ub85c \uc0ac\uc6a9\uc790 \uc694\uad6c\uc0ac\ud56d\uc744 \uc5b4\ub5bb\uac8c \uad6c\ud604\ud560 \uc218 \uc788\uc744\uc9c0 \uc81c\uc548\ud569\ub2c8\ub2e4\u3002\n        \"\"\".format(file_path)\n        file_analyzer_agent = create_react_agent(\n            model=model,\n            tools=[analyze_existing_file, analyze_parallelization] if analyze_existing_file and analyze_parallelization else [],\n            state_modifier=file_analyzer_system_prompt\n        )\n\n        # --- Researcher Agent (Web Search) ---\n        researcher_system_prompt = \"\"\"\n        \ub2f9\uc2e0\uc740 \ucf54\ub4dc \uc791\uc131\uc744 \uc704\ud55c \uc815\ubcf4\ub97c \uc218\uc9d1\ud558\ub294 \ub9ac\uc11c\ucc98\uc785\ub2c8\ub2e4. \ub2e4\uc74c \uaddc\uce59\uc744 \ub530\ub974\uc138\uc694:\n\n        1. \uc0ac\uc6a9\uc790 \uc694\uad6c\uc0ac\ud56d\uc744 \ubd84\uc11d\ud558\uace0, \ud544\uc694\ud55c \uae30\uc220 \uc815\ubcf4\ub97c \uc6f9\uc5d0\uc11c \uac80\uc0c9\ud569\ub2c8\ub2e4.\n        2. \uac80\uc0c9 \uacb0\uacfc\ub97c \ubc14\ud0d5\uc73c\ub85c \ucf54\ub4dc \uad6c\ud604\uc5d0 \ud544\uc694\ud55c \ud575\uc2ec \uc815\ubcf4\ub97c \uc694\uc57d\ud569\ub2c8\ub2e4\u3002\n        3. \ub2e4\uc74c \uc815\ubcf4\ub97c \ubc18\ub4dc\uc2dc \ud3ec\ud568\ud558\uc138\uc694:\n           - \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac/\ubaa8\ub4c8\n           - \uc8fc\uc694 \uc54c\uace0\ub9ac\uc998\uc774\ub098 \uae30\uc220 \uc124\uba85\n           - \uad6c\ud604 \uc2dc \uace0\ub824\ud574\uc57c \ud560 \uc8fc\uc694 \uc0ac\ud56d\n           - \ubaa8\ub4c8\ud654 \uac00\ub2a5\ud55c \uc694\uc18c \uc81c\uc548\n           - \uc791\uc5c5\uc758 \ubcd1\ub82c/\uc9c1\ub82c \ucc98\ub9ac \uac00\ub2a5\uc131 \ubd84\uc11d\n\n        4. \uc815\ubcf4\ub294 Coder\uac00 \uc774\ud574\ud558\uae30 \uc27d\uac8c \uad6c\uc870\ud654\ud558\uc5ec \uc81c\uacf5\ud558\uc138\uc694\u3002\n        5. \ub108\ubb34 \uc790\uc138\ud55c \ucf54\ub4dc \uad6c\ud604\ubcf4\ub2e4\ub294 \ud575\uc2ec \uac1c\ub150\uacfc \uad6c\uc870\uc5d0 \uc9d1\uc911\ud558\uc138\uc694\u3002\n        6. \ud2b9\ud788 \uc791\uc5c5\uc774 \ubcd1\ub82c \ucc98\ub9ac\uc5d0 \uc801\ud569\ud55c\uc9c0 \ubd84\uc11d\ud558\uace0, \uadf8 \uc774\uc720\ub97c \uba85\ud655\ud788 \uc124\uba85\ud558\uc138\uc694\u3002\n           - \uc608: \uc5ec\ub7ec \uc54c\uace0\ub9ac\uc998 \ube44\uad50\ub294 \ubcd1\ub82c \ucc98\ub9ac\uc5d0 \uc801\ud569\ud569\ub2c8\ub2e4\u3002\n           - \uc608: \ub370\uc774\ud130 \ubcc0\ud658 \u2192 \ud544\ud130\ub9c1 \u2192 \uc9d1\uacc4\uc640 \uac19\uc740 \uacfc\uc815\uc740 \uc9c1\ub82c \ucc98\ub9ac\uc5d0 \uc801\ud569\ud569\ub2c8\ub2e4\u3002\n        \"\"\"\n\n        researcher_agent = create_react_agent(\n            model=model,\n            tools=[tavily_search, analyze_parallelization] if tavily_search else [],\n            state_modifier=researcher_system_prompt\n        )\n\n        # --- Coder Agent (Code Writing) ---\n        coder_system_prompt = \"\"\"# Code Flow Generator Instructions\n\nYou are an expert in generating code and creating connected flows. Strictly follow these rules:\n\n1. Use the information provided by the Researcher to write code_blocks according to user requirements and then save it to the user's local file through the create_flow function.\n2. Modularize the code and divide it into multiple apps (nodes).\n3. The code_blocks specification for creating apps must follow example 3-1 below.\n3-1. The code field must contain executable Python code.\n3-2 When configuring each app, you must not only create functions but also call them.\n3-3 Variable names must always be in English!!\n\n4. Explicitly define the connection structure between apps:\n   - Serial connection: App A \u2192 App B \u2192 App C (sequential processing)\n   - Parallel connection: App A \u2192 [App B, App C, ...] (one app transmits data to multiple apps)\n   - Mixed connection: Combination of serial and parallel (complex workflow)\n\n5. Format for the connections dictionary to define connection structure:\n   Basic format: {\"source_app_id\": [\"target_app_id1\", \"target_app_id2\"]}\n   Detailed format: {\"source_app_id\": [{\"target\": \"target_app_id\", \"output\": \"output_name\", \"input\": \"input_name\"}]}\n\n6. You must create a complete code_blocks dictionary with all required fields and structure before calling the create_flow tool.\n\n7. IMPORTANT: Always ensure the code_blocks dictionary is properly initialized and populated before calling the create_flow tool.\n\n8. Always return the created code_blocks, connections, and connection_type as part of your response.\n\n9. You must call the provided tool (create_flow) after completing the task to save the workflow.\n\n10. inputs\uc758 \ud0c0\uc785\uc911 variable\uc740 \ubb34\uc870\uac74 str\uc73c\ub85c \ubcc0\uc218\ub97c \uc815\uc758\ud558\uac8c \ub418\uae30 \ub54c\ubb38\uc5d0 \ubcc0\uc218 \ud0c0\uc785\uc744 \uc7ac\uc815\uc758 \ud574\uc918\uc57c \ud55c\ub2e4 -> a = int(a)\n\n\"\"\"+\"\"\"11. save file_path is {}\"\"\".format(file_path)+\"\"\"\neg) \n#code_blocks sample \n{\n  \"apps\": {\n    \"app_id1(unique string)\": {\n      \"id\": \"app_id1(unique string)\",\n      \"title\": \"Load Data\",\n      \"inputs\": [{\"type\": \"variable\", \"name\": \"file_path\"}],\n      \"outputs\": [{\"type\": \"output\", \"name\": \"df\"}],\n      \"code\": \"import pandas as pd\\n\\ndef process(file_path):\\n    df = pd.read_csv(file_path)\\n    return df\\ndf = process(file_path)\",\n    },\n    \"app_id2(unique string)\": {\n      \"id\": \"app_id2(unique string)\",\n      \"title\": \"Data Preprocessing\",\n      \"inputs\": [{\"type\": \"output\", \"name\": \"df\"}],\n      \"outputs\": [{\"type\": \"output\", \"name\": \"proceed_df\"}],\n      \"code\": \"def process(df):\\n    # Handle missing values\\n    proceed_df = df.fillna(0)\\n    return proceed_df\\nproceed_df = process(df)\",\n    }\n  }\n}\"\"\"+\"\"\"\n#Tool Calling\ncreate_flow(code_blocks, title, {}, connections, connection_type)\n\"\"\".format(file_path)\n\n        coder_agent = create_react_agent(\n            model=model,\n            tools=[create_flow] if create_flow else [],\n            state_modifier=coder_system_prompt,\n        )\n\n        # --- Supervisor Agent (Task Management) ---\n        supervisor_system_prompt = \"\"\"\n        \ub2f9\uc2e0\uc740 \ub2e4\uc74c \uc791\uc5c5\uc790\ub4e4 \uac04\uc758 \ub300\ud654\ub97c \uad00\ub9ac\ud558\ub294 \uc288\ud37c\ubc14\uc774\uc800\uc785\ub2c8\ub2e4.\n\n        \uac01 \uc791\uc5c5\uc790\ub294 \ud2b9\uc815 \uc791\uc5c5\uc744 \uc218\ud589\ud558\uace0 \uacb0\uacfc\uc640 \uc0c1\ud0dc\ub97c \uc751\ub2f5\ud569\ub2c8\ub2e4:\n\n        - File_Analyzer: \uac00\uc7a5 \uba3c\uc800 \ud30c\uc77c\uc744 \uc5f4\uc5b4 \uae30\uc874 \uc6cc\ud06c\ud50c\ub85c\uc6b0\uac00 \uc5b4\ub5a4 \ud615\uc2dd\uc73c\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\ub294\uc9c0 \uba3c\uc800 \ubd84\uc11d\ud569\ub2c8\ub2e4\u3002\n        - Researcher: \uc6f9\uc5d0\uc11c \uc815\ubcf4\ub97c \uac80\uc0c9\ud558\uace0 \ucf54\ub4dc \uad6c\ud604\uc5d0 \ud544\uc694\ud55c \uc815\ubcf4\ub97c \uc218\uc9d1\ud569\ub2c8\ub2e4. \ub610\ud55c \uc791\uc5c5\uc774 \ubcd1\ub82c \ucc98\ub9ac\uc5d0 \uc801\ud569\ud55c\uc9c0\ub3c4 \ubd84\uc11d\ud569\ub2c8\ub2e4\u3002\n        - Coder: \uc218\uc9d1\ub41c \uc815\ubcf4\ub97c \ubc14\ud0d5\uc73c\ub85c \ucf54\ub4dc\ub97c \uc791\uc131\ud558\uace0 \ud30c\uc77c\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc801\uc808\ud55c \uc5f0\uacb0 \uc720\ud615(\ubcd1\ub82c/\uc9c1\ub82c)\uc744 \uc120\ud0dd\ud558\uc5ec \uad6c\ud604\ud569\ub2c8\ub2e4\u3002\n\n        \ud604\uc7ac \ub300\ud654\uc640 \uc0c1\ud669\uc744 \ubc14\ud0d5\uc73c\ub85c \ub2e4\uc74c\uc5d0 \uc5b4\ub5a4 \uc791\uc5c5\uc790\uac00 \uc791\uc5c5\uc744 \uc218\ud589\ud574\uc57c \ud558\ub294\uc9c0\uff0c\n        \ub610\ub294 \ubaa8\ub4e0 \uc791\uc5c5\uc774 \uc644\ub8cc\ub418\uc5c8\ub294\uc9c0(FINISH) \uacb0\uc815\ud558\uc138\uc694\n        \"\"\"\n\n        supervisor_prompt = ChatPromptTemplate.from_messages([\n            (\"system\", supervisor_system_prompt),\n            MessagesPlaceholder(variable_name=\"messages\"),\n            (\"human\", \"\ub2f5\ubcc0\uc740 \ud55c\uad6d\uc5b4\ub85c \ud558\ub77c\uace0 \uc9c0\uc2dc \ubc0f \uc751\ub2f5\ud558\uc2dc\uc624.\\\n            \uc704 \ub300\ud654\ub97c \ubc14\ud0d5\uc73c\ub85c, \ub2e4\uc74c\uc5d0 \ub204\uac00 \uc791\uc5c5\ud574\uc57c \ud560\uae4c\uc694? \ub2e4\uc74c \uc911 \ud558\ub098\ub97c \uc120\ud0dd\ud558\uc138\uc694: Researcher, Coder, File_Analyzer, FINISH\")\n        ])\n\n        # --- Agent Node Functions Definition ---\n        async def agent_node(state, agent, name):\n            if \"messages\" not in state or not state[\"messages\"]:\n          # \ub300\ud654\uac00 \uc5c6\uc73c\uba74 \ucd08\uae30 \uba54\uc2dc\uc9c0\n                state[\"messages\"] = [HumanMessage(content=f\"\uc791\uc5c5\uc744 \uc2dc\uc791\ud569\ub2c8\ub2e4. {name}\ub85c\uc11c \ub3c4\uc640\uc8fc\uc138\uc694\u3002\")]\n            else:\n                # \uba54\uc2dc\uc9c0\ub97c \uc77c\uc815 \uae38\uc774\ub85c truncate\n                state[\"messages\"] = truncate_messages(state['messages'])\n\n            # \uc5d0\uc774\uc804\ud2b8 \ud638\ucd9c\n            agent_response = await agent.ainvoke(state)\n            \n            # \ucd5c\uc2e0 \uba54\uc2dc\uc9c0(\uc5d0\uc774\uc804\ud2b8\uc758 \ucd5c\uc885 \uc751\ub2f5) \ucd94\uac00\n            result = {\n                \"messages\": state.get(\"messages\", []) + [\n                    HumanMessage(content=agent_response[\"messages\"][-1].content, name=name)\n                ]\n            }\n            \n            # \uae30\uc874 state\ub97c \ubcf4\uc874\n            for key in [\"file_path\", \"code_blocks\", \"parallel_required\", \"connections\", \"connection_type\", \"iteration_count\"]:\n                if key in state:\n                    result[key] = state[key]\n\n            # \ub9cc\uc57d Coder\uc758 \uc751\ub2f5\uc774\uba74, JSON \ud30c\uc2f1\uc744 \uc2dc\ub3c4\n            if name == \"Coder\":\n                final_text = agent_response[\"messages\"][-1].content\n                try:\n                    # LLM\uc774 JSON\uc73c\ub85c \uc751\ub2f5\ud55c\ub2e4\uace0 \uac00\uc815\n                    parsed = json.loads(final_text)\n                    # code_blocks / connections / connection_type \ucd94\ucd9c\n                    if \"code_blocks\" in parsed:\n                        result[\"code_blocks\"] = parsed[\"code_blocks\"]\n                    if \"connections\" in parsed:\n                        result[\"connections\"] = parsed[\"connections\"]\n                    if \"connection_type\" in parsed:\n                        result[\"connection_type\"] = parsed[\"connection_type\"]\n                except json.JSONDecodeError:\n                    # JSON \ud30c\uc2f1 \uc2e4\ud328 \uc2dc \ub85c\uadf8\ub9cc\n                    print('json \ud30c\uc2f1 \uc2e4\ud328')\n            \n            return result\n\n        # Node wrapper functions (async)\n        file_analyzer_node = functools.partial(agent_node, agent=file_analyzer_agent, name=\"File_Analyzer\")\n        researcher_node = functools.partial(agent_node, agent=researcher_agent, name=\"Researcher\")\n        coder_node = functools.partial(agent_node, agent=coder_agent, name=\"Coder\")\n\n        async def supervisor_agent_node(state):\n            supervisor_chain = supervisor_prompt | model.with_structured_output(RouteResponse)\n            response = await supervisor_chain.ainvoke(state)\n            \n            result = {\"next\": response.next if response.next else \"Researcher\"}\n            print(f\"{result['next']} \uc9c4\ud589\uc911\")\n\n            # Preserve all state values\n            for key in [\"file_path\", \"code_blocks\", \"parallel_required\", \"connections\", \"connection_type\", \"iteration_count\"]:\n                if key in state:\n                    result[key] = state[key]\n            \n            return result\n\n        # --- Graph Configuration ---\n        members = [\"Researcher\", \"Coder\", \"File_Analyzer\"]\n        workflow = StateGraph(AgentState)\n\n        workflow.add_node(\"Researcher\", researcher_node)\n        workflow.add_node(\"Coder\", coder_node)\n        workflow.add_node(\"File_Analyzer\", file_analyzer_node)\n        workflow.add_node(\"Supervisor\", supervisor_agent_node)\n        for member in members:\n            workflow.add_edge(member, \"Supervisor\")\n\n        conditional_map = {k: k for k in members}\n        conditional_map[\"FINISH\"] = END\n\n        def get_next(state):\n            return state[\"next\"]\n\n        workflow.add_conditional_edges(\"Supervisor\", get_next, conditional_map)\n        workflow.add_edge(START, \"Supervisor\")\n\n        graph = workflow.compile(checkpointer=MemorySaver())\n\n        # --- Execution ---\n        inputs = {\n            \"file_path\": file_path,\n            \"messages\": [\n                HumanMessage(content=query)\n            ],\n            \"code_blocks\": {},  # Initialize empty dictionary\n            \"connections\": {},   # Initialize empty dictionary\n            \"connection_type\": \"serial\",  # Default connection type\n            \"parallel_required\": False,   # Default parallelization flag\n            \"iteration_count\": 0,         # Initialize iteration counter\n        }\n        \n        result = await graph.ainvoke(inputs, config={\n            \"thread_id\": str(uuid.uuid4()),\n        })\n        return result\n\n# Main execution function\nasync def call_function(query, file_path):\n    result = await generate_workflow(query, file_path)\n    return result\n\ndef main():\n    result = asyncio.run(call_function(query, file_path))\n    print(result['messages'][-1].content)\n\nmain()", "api": "", "html": "", "js": "", "css": ""}, "fyfxhb8pbb06leop": {"id": "fyfxhb8pbb06leop", "title": "new app", "version": "1.0.0", "description": "", "cdn": {"js": [], "css": []}, "inputs": [], "outputs": [], "code": "import os\nimport operator\nimport functools\nimport uuid\nimport json\nimport time\nfrom typing import Sequence, Literal\nfrom typing import Annotated\nfrom typing_extensions import TypedDict\nfrom pydantic import BaseModel\n# --- MCP \ud074\ub77c\uc774\uc5b8\ud2b8 \uc124\uc815 \ucd94\uac00 ---\nimport asyncio\nfrom mcp import ClientSession\nfrom mcp.client.stdio import stdio_client\nfrom langchain_mcp_adapters.tools import load_mcp_tools\nfrom mcp import StdioServerParameters\nfrom langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langchain.tools import StructuredTool\nfrom langgraph.prebuilt import create_react_agent\n\n\nfrom langchain_openai import ChatOpenAI\nfrom langchain_openai import ChatOpenAI\nfrom langchain.schema import AIMessage, HumanMessage, SystemMessage\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableParallel, RunnablePassthrough\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_xai import ChatXAI\n\n\n'''\nmodel = ChatOpenAI(\n    model=\"gpt-4o\",\n    openai_api_key=os.environ.get(\"OPENAI_API_KEY\", \"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\")\n)\n'''\n\n# \ube44\ub3d9\uae30 \ud568\uc218\ub85c MCP \ub3c4\uad6c \ub85c\ub4dc \ubc0f StructuredTool\ub85c \ubcc0\ud658\nasync def load_tools():\n    async with MultiServerMCPClient(\n        {\n            \"test\": {\n                \"url\": \"http://220.82.71.6:8000/sse\",\n                \"transport\": \"sse\",\n            }\n        }\n    ) as client:\n        agent = create_react_agent(model, client.get_tools())\n        math_response = await agent.ainvoke({\"messages\": \"1053\ud68c\ucc28 \ub85c\ub610\ubc88\ud638 \uc54c\ub824\uc918\"})  # MCP \ub3c4\uad6c \uac00\uc838\uc624\uae30\n\n    return math_response\n\nprint(asyncio.run(load_tools())['messages'][-1].content)", "api": "", "html": "", "js": "", "css": ""}}, "description": "", "featured": "", "flow": {"b6uew1c7epof7qpe-1743490906694": {"app_id": "b6uew1c7epof7qpe", "class": "", "data": {"file_path": "/Users/ijaemun/Desktop/dizest/test/data/test.dwp", "query": "\uc778\ud2b8 100\uac1c\uc758 \ubb34\uc791\uc704 \ub9ac\uc2a4\ud2b8\ub97c \uc0dd\uc131\ud558\uace0 \ubc84\ube14\uc815\ub82c\uacfc \ud035\uc815\ub82c\uc744 \uc2dc\uac04 \ube44\uad50\ud558\ub294 \uc6cc\ud06c\ud50c\ub85c\uc6b0\ub97c \ub9cc\ub4e4\uc5b4\uc918", "server_url": "172.16.0.40"}, "active": true, "description": "", "id": "b6uew1c7epof7qpe-1743490906694", "inputs": {"query": {"connections": []}}, "name": "", "outputs": {}, "pos_x": -3115, "pos_y": -899, "typenode": false, "width": 546, "height": 460}}, "logo": "", "title": "test", "version": "", "visibility": "private", "extra": {}, "favorite": "0", "category": "", "id": "dizest_MCP_client/dizest_MCP_client.dwp", "kernel_id": "root-421cd146-1b5e-11f0-8435-246e96766138", "executable": null, "executable_name": "base"}